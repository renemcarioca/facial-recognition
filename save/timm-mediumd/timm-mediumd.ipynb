{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess import Preprocess\n",
    "from urllib.request import urlopen\n",
    "import timm\n",
    "import torch\n",
    "import functools\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRANSFORM = transforms.ToTensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:159: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Renan\\.cache\\huggingface\\hub\\models--timm--vit_mediumd_patch16_reg4_gap_256.sbb_in12k_ft_in1k. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "class TIMM:\n",
    "    def __init__(self):\n",
    "        # https://huggingface.co/timm/vit_mediumd_patch16_reg4_gap_256.sbb_in12k_ft_in1k\n",
    "        self.model = timm.create_model(\n",
    "            'vit_mediumd_patch16_reg4_gap_256.sbb_in12k_ft_in1k',\n",
    "            pretrained=True,\n",
    "            num_classes=0,  # remove classifier nn.Linear\n",
    "        )\n",
    "        self.model.eval()\n",
    "\n",
    "        # get model specific transforms (normalization, resize)\n",
    "        data_config = timm.data.resolve_model_data_config(self.model)\n",
    "        self.transforms = timm.data.create_transform(**data_config, is_training=False)\n",
    "\n",
    "    @functools.lru_cache(maxsize=None)\n",
    "    def extract(self, img) -> torch.Tensor:\n",
    "        with torch.no_grad():\n",
    "            return self.model(self.transforms(img).unsqueeze(0))[0]\n",
    "\n",
    "timm_model = TIMM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforma cada par em uma linha de uma ndarray (é quem criou os CSVs dev_train e dev_val)\n",
    "def pairs_as_ndarray(pairs):\n",
    "    result = []\n",
    "    for i, pair in enumerate(pairs):\n",
    "        image1, image2, label = pair\n",
    "        print(f'Progress: {i}/{len(pairs)}         ', end='\\r')\n",
    "        attr1 = timm_model.extract(image1)\n",
    "        attr2 = timm_model.extract(image2)\n",
    "        row = np.concatenate((attr1, attr2, [label]))\n",
    "        result.append(row)\n",
    "    return np.array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 999/1000          \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((2200, 1025), (1000, 1025))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_train = pairs_as_ndarray(Preprocess.load_train_pairs(transform=TRANSFORM))\n",
    "dev_val = pairs_as_ndarray(Preprocess.load_test_pairs(transform=TRANSFORM))\n",
    "# Load from .npy\n",
    "# dev_train = np.load('dev_train.npy')\n",
    "# dev_val = np.load('dev_val.npy')\n",
    "dev_train.shape, dev_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the arrays\n",
    "np.save('dev_train.npy', dev_train)\n",
    "np.save('dev_val.npy', dev_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2200, 1024), (2200,), (1000, 1024), (1000,))"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = dev_train[:, :-1]\n",
    "y_train = dev_train[:, -1]\n",
    "X_val = dev_val[:, :-1]\n",
    "y_val = dev_val[:, -1]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "\n",
    "X_train.shape, y_train.shape, X_val.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'C': 1e-05, 'solver': 'newton-cg'}\n",
      "Best cross-validation score:  0.5913636363636363\n"
     ]
    }
   ],
   "source": [
    "### Regressão logística\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'C': np.logspace(-5, 5, 5),\n",
    "    'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "}\n",
    "grid_search = GridSearchCV(LogisticRegression(max_iter=10000), param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters: \", grid_search.best_params_)\n",
    "print(\"Best cross-validation score: \", grid_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.6381818181818182\n",
      "Val accuracy: 0.613\n"
     ]
    }
   ],
   "source": [
    "\n",
    "logreg_model = LogisticRegression(**grid_search.best_params_)\n",
    "logreg_model.fit(X_train, y_train)\n",
    "print('Train accuracy:', accuracy_score(y_train, logreg_model.predict(X_train)))\n",
    "print('Val accuracy:', accuracy_score(y_val, logreg_model.predict(X_val)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_depth': 20}\n",
      "Best cross-validation score:  0.6972727272727273\n"
     ]
    }
   ],
   "source": [
    "\n",
    "### Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_dist = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "rf_random_search = RandomizedSearchCV(RandomForestClassifier(), param_distributions=param_dist, n_iter=10, cv=5)\n",
    "rf_random_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters: \", rf_random_search.best_params_)\n",
    "print(\"Best cross-validation score: \", rf_random_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 1.0\n",
      "Val accuracy: 0.721\n"
     ]
    }
   ],
   "source": [
    "\n",
    "rf_model = RandomForestClassifier(**rf_random_search.best_params_)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "print('Train accuracy:', accuracy_score(y_train, rf_model.predict(X_train)))\n",
    "print('Val accuracy:', accuracy_score(y_val, rf_model.predict(X_val)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 00m 27s]\n",
      "val_accuracy: 0.7890000104904175\n",
      "\n",
      "Best val_accuracy So Far: 0.7895999908447265\n",
      "Total elapsed time: 00h 02m 29s\n",
      "Results summary\n",
      "Results in runs\\nn-timm-mediumd\n",
      "Showing 10 best trials\n",
      "Objective(name=\"val_accuracy\", direction=\"max\")\n",
      "\n",
      "Trial 0 summary\n",
      "Hyperparameters:\n",
      "num_layers: 3\n",
      "units_0: 32\n",
      "learning_rate: 0.01\n",
      "units_1: 4\n",
      "units_2: 4\n",
      "Score: 0.7895999908447265\n",
      "\n",
      "Trial 4 summary\n",
      "Hyperparameters:\n",
      "num_layers: 1\n",
      "units_0: 20\n",
      "learning_rate: 0.01\n",
      "units_1: 8\n",
      "units_2: 32\n",
      "Score: 0.7890000104904175\n",
      "\n",
      "Trial 3 summary\n",
      "Hyperparameters:\n",
      "num_layers: 1\n",
      "units_0: 24\n",
      "learning_rate: 0.0001\n",
      "units_1: 24\n",
      "units_2: 32\n",
      "Score: 0.7769999861717224\n",
      "\n",
      "Trial 1 summary\n",
      "Hyperparameters:\n",
      "num_layers: 1\n",
      "units_0: 12\n",
      "learning_rate: 0.0001\n",
      "units_1: 20\n",
      "units_2: 20\n",
      "Score: 0.7613999962806701\n",
      "\n",
      "Trial 2 summary\n",
      "Hyperparameters:\n",
      "num_layers: 3\n",
      "units_0: 12\n",
      "learning_rate: 0.0001\n",
      "units_1: 8\n",
      "units_2: 32\n",
      "Score: 0.7428000092506408\n"
     ]
    }
   ],
   "source": [
    "\n",
    "### Rede neural\n",
    "import keras_tuner as kt\n",
    "import keras\n",
    "\n",
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    # Tune the number of layers\n",
    "    for i in range(hp.Int('num_layers', 1, 3)):\n",
    "        model.add(keras.layers.Dense(units=hp.Int('units_' + str(i),\n",
    "                                                min_value=4,\n",
    "                                                max_value=32,\n",
    "                                                step=4),\n",
    "                                   activation='relu'))\n",
    "    model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Tune the learning rate for the optimizer\n",
    "    # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "tuner = kt.RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=5,\n",
    "    executions_per_trial=5,\n",
    "    directory='runs',\n",
    "    project_name=f'nn-timm-mediumd')\n",
    "\n",
    "tuner.search_space_summary()\n",
    "\n",
    "tuner.search(X_train, y_train, epochs=40, validation_data=(X_val, y_val))\n",
    "\n",
    "tuner.results_summary()\n",
    "\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials = 10)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6016 - loss: 0.6555 - val_accuracy: 0.7410 - val_loss: 0.5248\n",
      "Epoch 2/40\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8060 - loss: 0.4325 - val_accuracy: 0.7630 - val_loss: 0.4970\n",
      "Epoch 3/40\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8748 - loss: 0.2999 - val_accuracy: 0.7730 - val_loss: 0.5630\n",
      "Epoch 4/40\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9029 - loss: 0.2459 - val_accuracy: 0.7740 - val_loss: 0.6833\n",
      "Epoch 5/40\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9437 - loss: 0.1429 - val_accuracy: 0.7730 - val_loss: 0.7008\n",
      "Epoch 6/40\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9318 - loss: 0.1857 - val_accuracy: 0.7720 - val_loss: 0.8254\n",
      "Epoch 7/40\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9356 - loss: 0.1371 - val_accuracy: 0.7670 - val_loss: 0.7946\n",
      "Epoch 8/40\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9650 - loss: 0.1047 - val_accuracy: 0.7650 - val_loss: 0.9917\n",
      "Epoch 9/40\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9617 - loss: 0.0927 - val_accuracy: 0.7770 - val_loss: 0.8725\n",
      "Epoch 10/40\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9648 - loss: 0.0857 - val_accuracy: 0.7920 - val_loss: 0.8712\n",
      "Epoch 11/40\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9781 - loss: 0.0509 - val_accuracy: 0.7820 - val_loss: 1.0530\n",
      "Epoch 12/40\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9845 - loss: 0.0464 - val_accuracy: 0.7690 - val_loss: 1.1786\n",
      "Epoch 13/40\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9794 - loss: 0.0461 - val_accuracy: 0.7850 - val_loss: 0.9970\n",
      "Epoch 14/40\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 952us/step - accuracy: 0.9769 - loss: 0.0439 - val_accuracy: 0.7790 - val_loss: 1.3105\n",
      "Epoch 15/40\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 978us/step - accuracy: 0.9899 - loss: 0.0199 - val_accuracy: 0.7720 - val_loss: 1.1519\n",
      "Epoch 16/40\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 983us/step - accuracy: 0.9888 - loss: 0.0455 - val_accuracy: 0.7760 - val_loss: 1.4626\n",
      "Epoch 17/40\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9973 - loss: 0.0074 - val_accuracy: 0.7800 - val_loss: 1.6225\n",
      "Epoch 18/40\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9838 - loss: 0.0518 - val_accuracy: 0.7610 - val_loss: 1.6328\n",
      "Epoch 19/40\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9798 - loss: 0.0618 - val_accuracy: 0.7660 - val_loss: 1.3158\n",
      "Epoch 20/40\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9886 - loss: 0.0269 - val_accuracy: 0.7730 - val_loss: 1.1421\n",
      "Epoch 21/40\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9901 - loss: 0.0285 - val_accuracy: 0.7610 - val_loss: 1.4504\n",
      "Epoch 22/40\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9937 - loss: 0.0153 - val_accuracy: 0.7770 - val_loss: 1.6900\n",
      "Epoch 23/40\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9885 - loss: 0.0352 - val_accuracy: 0.7640 - val_loss: 1.4575\n",
      "Epoch 24/40\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9935 - loss: 0.0172 - val_accuracy: 0.7740 - val_loss: 1.5875\n",
      "Epoch 25/40\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9896 - loss: 0.0215 - val_accuracy: 0.7720 - val_loss: 1.4009\n",
      "Epoch 26/40\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9950 - loss: 0.0139 - val_accuracy: 0.7780 - val_loss: 1.4446\n",
      "Epoch 27/40\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9915 - loss: 0.0205 - val_accuracy: 0.7740 - val_loss: 1.5206\n",
      "Epoch 28/40\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9937 - loss: 0.0146 - val_accuracy: 0.7680 - val_loss: 1.2962\n",
      "Epoch 29/40\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9962 - loss: 0.0121 - val_accuracy: 0.7860 - val_loss: 1.7133\n",
      "Epoch 30/40\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9913 - loss: 0.0388 - val_accuracy: 0.7950 - val_loss: 1.2091\n",
      "Epoch 31/40\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9978 - loss: 0.0103 - val_accuracy: 0.7850 - val_loss: 1.4784\n",
      "Epoch 32/40\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9884 - loss: 0.0316 - val_accuracy: 0.7860 - val_loss: 1.5034\n",
      "Epoch 33/40\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9981 - loss: 0.0073 - val_accuracy: 0.7780 - val_loss: 1.6338\n",
      "Epoch 34/40\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9835 - loss: 0.0470 - val_accuracy: 0.7750 - val_loss: 1.4333\n",
      "Epoch 35/40\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9930 - loss: 0.0159 - val_accuracy: 0.7840 - val_loss: 1.5172\n",
      "Epoch 36/40\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9958 - loss: 0.0151 - val_accuracy: 0.7920 - val_loss: 1.3039\n",
      "Epoch 37/40\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9986 - loss: 0.0068 - val_accuracy: 0.7850 - val_loss: 1.2122\n",
      "Epoch 38/40\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9956 - loss: 0.0152 - val_accuracy: 0.7790 - val_loss: 1.6940\n",
      "Epoch 39/40\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 9.5263e-04 - val_accuracy: 0.7820 - val_loss: 1.9167\n",
      "Epoch 40/40\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 5.1453e-04 - val_accuracy: 0.7830 - val_loss: 1.9837\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,800</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">132</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │        \u001b[38;5;34m32,800\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_15 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │           \u001b[38;5;34m132\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_16 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │            \u001b[38;5;34m20\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_17 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m5\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">98,873</span> (386.23 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m98,873\u001b[0m (386.23 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">32,957</span> (128.74 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m32,957\u001b[0m (128.74 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">65,916</span> (257.49 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m65,916\u001b[0m (257.49 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "best_hp = tuner.get_best_hyperparameters()[0]\n",
    "nn_model = tuner.hypermodel.build(best_hp)\n",
    "nn_model.fit(X_train, y_train, epochs=40, validation_data=(X_val, y_val))\n",
    "nn_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490us/step - accuracy: 1.0000 - loss: 1.7695e-04\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 821us/step - accuracy: 0.7719 - loss: 1.7912\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.0, 0.7829999923706055)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train_accuracy = nn_model.evaluate(X_train, y_train)[1]\n",
    "val_accuracy = nn_model.evaluate(X_val, y_val)[1]\n",
    "train_accuracy, val_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'C': 10.0, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "Best cross-validation score:  0.7863636363636364\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "### SVM\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Define the parameter grid for grid search\n",
    "param_grid = {\n",
    "    'C': np.logspace(-3, 2, base=10, num=6),\n",
    "    'kernel': ['rbf', 'sigmoid'],\n",
    "    'gamma': np.logspace(-3, 2, base=10, num=6)\n",
    "}\n",
    "\n",
    "# Perform grid search to find the best parameters\n",
    "grid_search = GridSearchCV(SVC(), param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters: \", grid_search.best_params_)\n",
    "print(\"Best cross-validation score: \", grid_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 1.0\n",
      "Val accuracy: 0.795\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create an SVM model with the best parameters\n",
    "svm_model = SVC(**grid_search.best_params_)\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "print('Train accuracy:', accuracy_score(y_train, svm_model.predict(X_train)))\n",
    "print('Val accuracy:', accuracy_score(y_val, svm_model.predict(X_val)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
