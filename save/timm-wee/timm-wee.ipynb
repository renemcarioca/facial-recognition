{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import timm\n",
    "import torch\n",
    "import functools\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRANSFORM = transforms.ToTensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TIMM:\n",
    "    def __init__(self):\n",
    "        # https://huggingface.co/timm/vit_wee_patch16_reg1_gap_256.sbb_in1k\n",
    "        self.model = timm.create_model(\n",
    "            'vit_wee_patch16_reg1_gap_256.sbb_in1k',\n",
    "            pretrained=True,\n",
    "            num_classes=0,  # remove classifier nn.Linear\n",
    "        )\n",
    "        self.model.eval()\n",
    "\n",
    "        # get model specific transforms (normalization, resize)\n",
    "        data_config = timm.data.resolve_model_data_config(self.model)\n",
    "        self.transforms = timm.data.create_transform(**data_config, is_training=False)\n",
    "\n",
    "    @functools.lru_cache(maxsize=None)\n",
    "    def extract(self, img) -> torch.Tensor:\n",
    "        with torch.no_grad():\n",
    "            return self.model(self.transforms(img).unsqueeze(0))[0]\n",
    "\n",
    "timm_model = TIMM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforma cada par em uma linha de uma ndarray (é quem criou os CSVs dev_train e dev_val)\n",
    "def pairs_as_ndarray(pairs):\n",
    "    result = []\n",
    "    for i, pair in enumerate(pairs):\n",
    "        image1, image2, label = pair\n",
    "        print(f'Progress: {i}/{len(pairs)}         ', end='\\r')\n",
    "        attr1 = timm_model.extract(image1)\n",
    "        attr2 = timm_model.extract(image2)\n",
    "        row = np.concatenate((attr1, attr2, [label]))\n",
    "        result.append(row)\n",
    "    return np.array(result)\n",
    "\n",
    "def duplicate_by_symmetry(x):\n",
    "    result = []\n",
    "    for row in x:\n",
    "        num_of_features = int((len(row) - 1) / 2)\n",
    "        left = row[:num_of_features]\n",
    "        right = row[num_of_features:-1]\n",
    "        label = row[-1]\n",
    "        result.append(np.concatenate((left, right, [label])))\n",
    "        result.append(np.concatenate((right, left, [label])))\n",
    "    return np.array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4400, 513), (1000, 513))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dev_train = pairs_as_ndarray(Preprocess.load_train_pairs(transform=TRANSFORM))\n",
    "# dev_val = pairs_as_ndarray(Preprocess.load_test_pairs(transform=TRANSFORM))\n",
    "# Load from .npy\n",
    "dev_train = duplicate_by_symmetry(np.load('dev_train.npy'))\n",
    "dev_val = np.load('dev_val.npy')\n",
    "dev_train.shape, dev_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save the arrays\n",
    "# np.save('dev_train.npy', dev_train)\n",
    "# np.save('dev_val.npy', dev_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4400, 512), (4400,), (1000, 512), (1000,))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = dev_train[:, :-1]\n",
    "y_train = dev_train[:, -1]\n",
    "X_val = dev_val[:, :-1]\n",
    "y_val = dev_val[:, -1]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "\n",
    "X_train.shape, y_train.shape, X_val.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'C': 0.0031622776601683794, 'solver': 'newton-cg'}\n",
      "Best cross-validation score:  0.5331818181818182\n"
     ]
    }
   ],
   "source": [
    "### Regressão logística\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'C': np.logspace(-5, 5, 5),\n",
    "    'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "}\n",
    "grid_search = GridSearchCV(LogisticRegression(max_iter=10000), param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters: \", grid_search.best_params_)\n",
    "print(\"Best cross-validation score: \", grid_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.6336363636363637\n",
      "Val accuracy: 0.591\n"
     ]
    }
   ],
   "source": [
    "\n",
    "logreg_model = LogisticRegression(**grid_search.best_params_)\n",
    "logreg_model.fit(X_train, y_train)\n",
    "print('Train accuracy:', accuracy_score(y_train, logreg_model.predict(X_train)))\n",
    "print('Val accuracy:', accuracy_score(y_val, logreg_model.predict(X_val)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'n_estimators': 200, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_depth': 20}\n",
      "Best cross-validation score:  0.6829545454545454\n"
     ]
    }
   ],
   "source": [
    "\n",
    "### Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_dist = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "rf_random_search = RandomizedSearchCV(RandomForestClassifier(), param_distributions=param_dist, n_iter=10, cv=5)\n",
    "rf_random_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters: \", rf_random_search.best_params_)\n",
    "print(\"Best cross-validation score: \", rf_random_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9972727272727273\n",
      "Val accuracy: 0.714\n"
     ]
    }
   ],
   "source": [
    "\n",
    "rf_model = RandomForestClassifier(**rf_random_search.best_params_)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "print('Train accuracy:', accuracy_score(y_train, rf_model.predict(X_train)))\n",
    "print('Val accuracy:', accuracy_score(y_val, rf_model.predict(X_val)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 00m 36s]\n",
      "val_accuracy: 0.7526000022888184\n",
      "\n",
      "Best val_accuracy So Far: 0.7543999910354614\n",
      "Total elapsed time: 00h 02m 44s\n",
      "Results summary\n",
      "Results in runs2\\nn-timm-wee\n",
      "Showing 10 best trials\n",
      "Objective(name=\"val_accuracy\", direction=\"max\")\n",
      "\n",
      "Trial 3 summary\n",
      "Hyperparameters:\n",
      "num_layers: 1\n",
      "units_0: 24\n",
      "learning_rate: 0.0001\n",
      "units_1: 32\n",
      "Score: 0.7543999910354614\n",
      "\n",
      "Trial 4 summary\n",
      "Hyperparameters:\n",
      "num_layers: 3\n",
      "units_0: 20\n",
      "learning_rate: 0.001\n",
      "units_1: 12\n",
      "units_2: 4\n",
      "Score: 0.7526000022888184\n",
      "\n",
      "Trial 2 summary\n",
      "Hyperparameters:\n",
      "num_layers: 2\n",
      "units_0: 32\n",
      "learning_rate: 0.01\n",
      "units_1: 24\n",
      "Score: 0.7508000016212464\n",
      "\n",
      "Trial 0 summary\n",
      "Hyperparameters:\n",
      "num_layers: 1\n",
      "units_0: 8\n",
      "learning_rate: 0.01\n",
      "Score: 0.7473999977111816\n",
      "\n",
      "Trial 1 summary\n",
      "Hyperparameters:\n",
      "num_layers: 2\n",
      "units_0: 12\n",
      "learning_rate: 0.001\n",
      "units_1: 4\n",
      "Score: 0.7425999999046325\n"
     ]
    }
   ],
   "source": [
    "\n",
    "### Rede neural\n",
    "import keras_tuner as kt\n",
    "import keras\n",
    "\n",
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    # Tune the number of layers\n",
    "    for i in range(hp.Int('num_layers', 1, 3)):\n",
    "        model.add(keras.layers.Dense(units=hp.Int('units_' + str(i),\n",
    "                                                min_value=4,\n",
    "                                                max_value=32,\n",
    "                                                step=4),\n",
    "                                   activation='relu'))\n",
    "    model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Tune the learning rate for the optimizer\n",
    "    # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "tuner = kt.RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=5,\n",
    "    executions_per_trial=5,\n",
    "    directory='runs2',\n",
    "    project_name=f'nn-timm-wee')\n",
    "\n",
    "tuner.search_space_summary()\n",
    "\n",
    "tuner.search(X_train, y_train, epochs=40, validation_data=(X_val, y_val))\n",
    "\n",
    "tuner.results_summary()\n",
    "\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials = 10)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5166 - loss: 0.8556 - val_accuracy: 0.5570 - val_loss: 0.7529\n",
      "Epoch 2/40\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 862us/step - accuracy: 0.5984 - loss: 0.7245 - val_accuracy: 0.5970 - val_loss: 0.6898\n",
      "Epoch 3/40\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 684us/step - accuracy: 0.6237 - loss: 0.6645 - val_accuracy: 0.6460 - val_loss: 0.6563\n",
      "Epoch 4/40\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 691us/step - accuracy: 0.6525 - loss: 0.6154 - val_accuracy: 0.6670 - val_loss: 0.6336\n",
      "Epoch 5/40\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 933us/step - accuracy: 0.6780 - loss: 0.5937 - val_accuracy: 0.6770 - val_loss: 0.6171\n",
      "Epoch 6/40\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 866us/step - accuracy: 0.7087 - loss: 0.5646 - val_accuracy: 0.6800 - val_loss: 0.6046\n",
      "Epoch 7/40\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 853us/step - accuracy: 0.7132 - loss: 0.5517 - val_accuracy: 0.6960 - val_loss: 0.5941\n",
      "Epoch 8/40\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 719us/step - accuracy: 0.7242 - loss: 0.5381 - val_accuracy: 0.7100 - val_loss: 0.5841\n",
      "Epoch 9/40\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 694us/step - accuracy: 0.7335 - loss: 0.5232 - val_accuracy: 0.7090 - val_loss: 0.5754\n",
      "Epoch 10/40\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 698us/step - accuracy: 0.7465 - loss: 0.5075 - val_accuracy: 0.7150 - val_loss: 0.5689\n",
      "Epoch 11/40\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696us/step - accuracy: 0.7633 - loss: 0.4910 - val_accuracy: 0.7210 - val_loss: 0.5615\n",
      "Epoch 12/40\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 688us/step - accuracy: 0.7680 - loss: 0.4813 - val_accuracy: 0.7210 - val_loss: 0.5571\n",
      "Epoch 13/40\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 859us/step - accuracy: 0.7897 - loss: 0.4582 - val_accuracy: 0.7240 - val_loss: 0.5526\n",
      "Epoch 14/40\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 747us/step - accuracy: 0.7821 - loss: 0.4624 - val_accuracy: 0.7240 - val_loss: 0.5490\n",
      "Epoch 15/40\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step - accuracy: 0.7969 - loss: 0.4489 - val_accuracy: 0.7230 - val_loss: 0.5461\n",
      "Epoch 16/40\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step - accuracy: 0.7963 - loss: 0.4437 - val_accuracy: 0.7220 - val_loss: 0.5430\n",
      "Epoch 17/40\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step - accuracy: 0.8190 - loss: 0.4164 - val_accuracy: 0.7200 - val_loss: 0.5404\n",
      "Epoch 18/40\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 768us/step - accuracy: 0.8233 - loss: 0.4225 - val_accuracy: 0.7290 - val_loss: 0.5385\n",
      "Epoch 19/40\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 834us/step - accuracy: 0.8076 - loss: 0.4280 - val_accuracy: 0.7280 - val_loss: 0.5365\n",
      "Epoch 20/40\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step - accuracy: 0.8238 - loss: 0.4133 - val_accuracy: 0.7250 - val_loss: 0.5356\n",
      "Epoch 21/40\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step - accuracy: 0.8267 - loss: 0.4085 - val_accuracy: 0.7300 - val_loss: 0.5350\n",
      "Epoch 22/40\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 885us/step - accuracy: 0.8311 - loss: 0.4023 - val_accuracy: 0.7300 - val_loss: 0.5327\n",
      "Epoch 23/40\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 730us/step - accuracy: 0.8361 - loss: 0.3958 - val_accuracy: 0.7330 - val_loss: 0.5314\n",
      "Epoch 24/40\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step - accuracy: 0.8445 - loss: 0.3818 - val_accuracy: 0.7340 - val_loss: 0.5318\n",
      "Epoch 25/40\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 797us/step - accuracy: 0.8490 - loss: 0.3772 - val_accuracy: 0.7330 - val_loss: 0.5317\n",
      "Epoch 26/40\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 739us/step - accuracy: 0.8465 - loss: 0.3728 - val_accuracy: 0.7320 - val_loss: 0.5297\n",
      "Epoch 27/40\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 870us/step - accuracy: 0.8471 - loss: 0.3748 - val_accuracy: 0.7290 - val_loss: 0.5308\n",
      "Epoch 28/40\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step - accuracy: 0.8474 - loss: 0.3670 - val_accuracy: 0.7280 - val_loss: 0.5305\n",
      "Epoch 29/40\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step - accuracy: 0.8502 - loss: 0.3631 - val_accuracy: 0.7330 - val_loss: 0.5301\n",
      "Epoch 30/40\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 714us/step - accuracy: 0.8593 - loss: 0.3543 - val_accuracy: 0.7330 - val_loss: 0.5290\n",
      "Epoch 31/40\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 878us/step - accuracy: 0.8650 - loss: 0.3480 - val_accuracy: 0.7350 - val_loss: 0.5292\n",
      "Epoch 32/40\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 743us/step - accuracy: 0.8574 - loss: 0.3508 - val_accuracy: 0.7320 - val_loss: 0.5289\n",
      "Epoch 33/40\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 780us/step - accuracy: 0.8798 - loss: 0.3298 - val_accuracy: 0.7350 - val_loss: 0.5285\n",
      "Epoch 34/40\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 772us/step - accuracy: 0.8699 - loss: 0.3386 - val_accuracy: 0.7360 - val_loss: 0.5296\n",
      "Epoch 35/40\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 775us/step - accuracy: 0.8699 - loss: 0.3306 - val_accuracy: 0.7360 - val_loss: 0.5292\n",
      "Epoch 36/40\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step - accuracy: 0.8794 - loss: 0.3141 - val_accuracy: 0.7360 - val_loss: 0.5293\n",
      "Epoch 37/40\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 793us/step - accuracy: 0.8776 - loss: 0.3273 - val_accuracy: 0.7410 - val_loss: 0.5286\n",
      "Epoch 38/40\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 833us/step - accuracy: 0.8764 - loss: 0.3229 - val_accuracy: 0.7390 - val_loss: 0.5307\n",
      "Epoch 39/40\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 797us/step - accuracy: 0.8778 - loss: 0.3190 - val_accuracy: 0.7390 - val_loss: 0.5315\n",
      "Epoch 40/40\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 719us/step - accuracy: 0.8807 - loss: 0.3122 - val_accuracy: 0.7370 - val_loss: 0.5336\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,312</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)             │        \u001b[38;5;34m12,312\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m25\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">37,013</span> (144.59 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m37,013\u001b[0m (144.59 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,337</span> (48.19 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m12,337\u001b[0m (48.19 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,676</span> (96.39 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m24,676\u001b[0m (96.39 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "best_hp = tuner.get_best_hyperparameters()[0]\n",
    "nn_model = tuner.hypermodel.build(best_hp)\n",
    "nn_model.fit(X_train, y_train, epochs=40, validation_data=(X_val, y_val))\n",
    "nn_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 350us/step - accuracy: 0.9076 - loss: 0.2914\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 504us/step - accuracy: 0.7523 - loss: 0.5253\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8886363506317139, 0.7369999885559082)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train_accuracy = nn_model.evaluate(X_train, y_train)[1]\n",
    "val_accuracy = nn_model.evaluate(X_val, y_val)[1]\n",
    "train_accuracy, val_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'C': 10.0, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "Best cross-validation score:  0.7227272727272727\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "### SVM\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Define the parameter grid for grid search\n",
    "param_grid = {\n",
    "    'C': np.logspace(-3, 2, base=10, num=6),\n",
    "    'kernel': ['rbf', 'sigmoid'],\n",
    "    'gamma': np.logspace(-3, 2, base=10, num=6)\n",
    "}\n",
    "\n",
    "# Perform grid search to find the best parameters\n",
    "grid_search = GridSearchCV(SVC(), param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters: \", grid_search.best_params_)\n",
    "print(\"Best cross-validation score: \", grid_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9813636363636363\n",
      "Val accuracy: 0.749\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create an SVM model with the best parameters\n",
    "svm_model = SVC(**grid_search.best_params_)\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "print('Train accuracy:', accuracy_score(y_train, svm_model.predict(X_train)))\n",
    "print('Val accuracy:', accuracy_score(y_val, svm_model.predict(X_val)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
