{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "import torch\n",
    "from torch import nn\n",
    "import functools\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4400, 1025), (1000, 1025))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def duplicate_by_symmetry(x):\n",
    "    result = []\n",
    "    for row in x:\n",
    "        num_of_features = int((len(row) - 1) / 2)\n",
    "        left = row[:num_of_features]\n",
    "        right = row[num_of_features:-1]\n",
    "        label = row[-1]\n",
    "        result.append(np.concatenate((left, right, [label])))\n",
    "        result.append(np.concatenate((right, left, [label])))\n",
    "    return np.array(result)\n",
    "\n",
    "# Load from .npy\n",
    "dev_train = duplicate_by_symmetry(np.load('dev-train.npy'))\n",
    "dev_val = np.load('dev-val.npy')\n",
    "dev_train.shape, dev_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4400, 1024), (4400,), (1000, 1024), (1000,))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = dev_train[:, :-1]\n",
    "y_train = dev_train[:, -1]\n",
    "X_val = dev_val[:, :-1]\n",
    "y_val = dev_val[:, -1]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "\n",
    "X_train.shape, y_train.shape, X_val.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\sklearn\\utils\\optimize.py:99: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\utils\\optimize.py:311: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\utils\\optimize.py:99: LineSearchWarning: The line search algorithm did not converge\n",
      "  ret = line_search_wolfe2(\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\utils\\optimize.py:311: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'C': 0.0031622776601683794, 'solver': 'lbfgs'}\n",
      "Best cross-validation score:  0.5836363636363636\n"
     ]
    }
   ],
   "source": [
    "### Regressão logística\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'C': np.logspace(-5, 5, 5),\n",
    "    'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "}\n",
    "grid_search = GridSearchCV(LogisticRegression(max_iter=10000), param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters: \", grid_search.best_params_)\n",
    "print(\"Best cross-validation score: \", grid_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.6827272727272727\n",
      "Val accuracy: 0.6\n"
     ]
    }
   ],
   "source": [
    "\n",
    "logreg_model = LogisticRegression(**grid_search.best_params_)\n",
    "logreg_model.fit(X_train, y_train)\n",
    "print('Train accuracy:', accuracy_score(y_train, logreg_model.predict(X_train)))\n",
    "print('Val accuracy:', accuracy_score(y_val, logreg_model.predict(X_val)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_depth': None}\n",
      "Best cross-validation score:  0.8940909090909092\n"
     ]
    }
   ],
   "source": [
    "\n",
    "### Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_dist = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "rf_random_search = RandomizedSearchCV(RandomForestClassifier(), param_distributions=param_dist, n_iter=10, cv=5)\n",
    "rf_random_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters: \", rf_random_search.best_params_)\n",
    "print(\"Best cross-validation score: \", rf_random_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9943181818181818\n",
      "Val accuracy: 0.863\n"
     ]
    }
   ],
   "source": [
    "\n",
    "rf_model = RandomForestClassifier(**rf_random_search.best_params_)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "print('Train accuracy:', accuracy_score(y_train, rf_model.predict(X_train)))\n",
    "print('Val accuracy:', accuracy_score(y_val, rf_model.predict(X_val)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 00m 34s]\n",
      "val_accuracy: 0.870800006389618\n",
      "\n",
      "Best val_accuracy So Far: 0.8802000045776367\n",
      "Total elapsed time: 00h 02m 42s\n",
      "Results summary\n",
      "Results in runs2\\nn-timm-siamese-mediumd\n",
      "Showing 10 best trials\n",
      "Objective(name=\"val_accuracy\", direction=\"max\")\n",
      "\n",
      "Trial 0 summary\n",
      "Hyperparameters:\n",
      "num_layers: 2\n",
      "units_0: 16\n",
      "learning_rate: 0.001\n",
      "units_1: 4\n",
      "Score: 0.8802000045776367\n",
      "\n",
      "Trial 3 summary\n",
      "Hyperparameters:\n",
      "num_layers: 2\n",
      "units_0: 20\n",
      "learning_rate: 0.01\n",
      "units_1: 4\n",
      "Score: 0.8757999897003174\n",
      "\n",
      "Trial 4 summary\n",
      "Hyperparameters:\n",
      "num_layers: 2\n",
      "units_0: 20\n",
      "learning_rate: 0.0001\n",
      "units_1: 16\n",
      "Score: 0.870800006389618\n",
      "\n",
      "Trial 1 summary\n",
      "Hyperparameters:\n",
      "num_layers: 2\n",
      "units_0: 16\n",
      "learning_rate: 0.0001\n",
      "units_1: 28\n",
      "Score: 0.8692000031471252\n",
      "\n",
      "Trial 2 summary\n",
      "Hyperparameters:\n",
      "num_layers: 1\n",
      "units_0: 4\n",
      "learning_rate: 0.0001\n",
      "units_1: 12\n",
      "Score: 0.8085999965667725\n"
     ]
    }
   ],
   "source": [
    "\n",
    "### Rede neural\n",
    "import keras_tuner as kt\n",
    "import keras\n",
    "\n",
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    # Tune the number of layers\n",
    "    for i in range(hp.Int('num_layers', 1, 3)):\n",
    "        model.add(keras.layers.Dense(units=hp.Int('units_' + str(i),\n",
    "                                                min_value=4,\n",
    "                                                max_value=32,\n",
    "                                                step=4),\n",
    "                                   activation='relu'))\n",
    "    model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Tune the learning rate for the optimizer\n",
    "    # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "tuner = kt.RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=5,\n",
    "    executions_per_trial=5,\n",
    "    directory='runs2',\n",
    "    project_name=f'nn-timm-siamese-mediumd')\n",
    "\n",
    "tuner.search_space_summary()\n",
    "\n",
    "tuner.search(X_train, y_train, epochs=40, validation_data=(X_val, y_val))\n",
    "\n",
    "tuner.results_summary()\n",
    "\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials = 10)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7135 - loss: 0.5398 - val_accuracy: 0.8200 - val_loss: 0.4138\n",
      "Epoch 2/40\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step - accuracy: 0.8758 - loss: 0.2903 - val_accuracy: 0.8470 - val_loss: 0.3746\n",
      "Epoch 3/40\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step - accuracy: 0.8984 - loss: 0.2507 - val_accuracy: 0.8490 - val_loss: 0.3669\n",
      "Epoch 4/40\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step - accuracy: 0.9157 - loss: 0.2177 - val_accuracy: 0.8390 - val_loss: 0.3790\n",
      "Epoch 5/40\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step - accuracy: 0.9209 - loss: 0.2130 - val_accuracy: 0.8430 - val_loss: 0.4090\n",
      "Epoch 6/40\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step - accuracy: 0.9372 - loss: 0.1857 - val_accuracy: 0.8590 - val_loss: 0.3636\n",
      "Epoch 7/40\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 916us/step - accuracy: 0.9411 - loss: 0.1777 - val_accuracy: 0.8500 - val_loss: 0.3698\n",
      "Epoch 8/40\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step - accuracy: 0.9393 - loss: 0.1572 - val_accuracy: 0.8660 - val_loss: 0.3667\n",
      "Epoch 9/40\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 799us/step - accuracy: 0.9458 - loss: 0.1517 - val_accuracy: 0.8640 - val_loss: 0.3808\n",
      "Epoch 10/40\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step - accuracy: 0.9501 - loss: 0.1466 - val_accuracy: 0.8550 - val_loss: 0.3794\n",
      "Epoch 11/40\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816us/step - accuracy: 0.9581 - loss: 0.1278 - val_accuracy: 0.8670 - val_loss: 0.3873\n",
      "Epoch 12/40\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step - accuracy: 0.9553 - loss: 0.1282 - val_accuracy: 0.8630 - val_loss: 0.3759\n",
      "Epoch 13/40\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step - accuracy: 0.9647 - loss: 0.1116 - val_accuracy: 0.8580 - val_loss: 0.3754\n",
      "Epoch 14/40\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 856us/step - accuracy: 0.9693 - loss: 0.1016 - val_accuracy: 0.8710 - val_loss: 0.3863\n",
      "Epoch 15/40\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 920us/step - accuracy: 0.9656 - loss: 0.1006 - val_accuracy: 0.8590 - val_loss: 0.4266\n",
      "Epoch 16/40\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step - accuracy: 0.9716 - loss: 0.0870 - val_accuracy: 0.8610 - val_loss: 0.4086\n",
      "Epoch 17/40\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step - accuracy: 0.9743 - loss: 0.0824 - val_accuracy: 0.8590 - val_loss: 0.4596\n",
      "Epoch 18/40\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step - accuracy: 0.9739 - loss: 0.0816 - val_accuracy: 0.8720 - val_loss: 0.3988\n",
      "Epoch 19/40\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step - accuracy: 0.9701 - loss: 0.0785 - val_accuracy: 0.8620 - val_loss: 0.4232\n",
      "Epoch 20/40\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step - accuracy: 0.9815 - loss: 0.0653 - val_accuracy: 0.8630 - val_loss: 0.4059\n",
      "Epoch 21/40\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 893us/step - accuracy: 0.9838 - loss: 0.0534 - val_accuracy: 0.8630 - val_loss: 0.4336\n",
      "Epoch 22/40\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 967us/step - accuracy: 0.9825 - loss: 0.0524 - val_accuracy: 0.8700 - val_loss: 0.4519\n",
      "Epoch 23/40\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 979us/step - accuracy: 0.9838 - loss: 0.0517 - val_accuracy: 0.8680 - val_loss: 0.4712\n",
      "Epoch 24/40\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 742us/step - accuracy: 0.9848 - loss: 0.0505 - val_accuracy: 0.8700 - val_loss: 0.4548\n",
      "Epoch 25/40\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9841 - loss: 0.0538 - val_accuracy: 0.8760 - val_loss: 0.4619\n",
      "Epoch 26/40\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 820us/step - accuracy: 0.9880 - loss: 0.0420 - val_accuracy: 0.8470 - val_loss: 0.5086\n",
      "Epoch 27/40\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 799us/step - accuracy: 0.9721 - loss: 0.0703 - val_accuracy: 0.8640 - val_loss: 0.4785\n",
      "Epoch 28/40\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 834us/step - accuracy: 0.9902 - loss: 0.0361 - val_accuracy: 0.8720 - val_loss: 0.5087\n",
      "Epoch 29/40\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step - accuracy: 0.9907 - loss: 0.0342 - val_accuracy: 0.8740 - val_loss: 0.4956\n",
      "Epoch 30/40\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 913us/step - accuracy: 0.9904 - loss: 0.0289 - val_accuracy: 0.8820 - val_loss: 0.5358\n",
      "Epoch 31/40\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step - accuracy: 0.9953 - loss: 0.0232 - val_accuracy: 0.8740 - val_loss: 0.5166\n",
      "Epoch 32/40\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step - accuracy: 0.9960 - loss: 0.0217 - val_accuracy: 0.8590 - val_loss: 0.5741\n",
      "Epoch 33/40\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 799us/step - accuracy: 0.9863 - loss: 0.0374 - val_accuracy: 0.8640 - val_loss: 0.5903\n",
      "Epoch 34/40\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step - accuracy: 0.9844 - loss: 0.0484 - val_accuracy: 0.8700 - val_loss: 0.5438\n",
      "Epoch 35/40\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - accuracy: 0.9949 - loss: 0.0236 - val_accuracy: 0.8780 - val_loss: 0.5569\n",
      "Epoch 36/40\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 778us/step - accuracy: 0.9979 - loss: 0.0152 - val_accuracy: 0.8710 - val_loss: 0.5673\n",
      "Epoch 37/40\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 797us/step - accuracy: 0.9992 - loss: 0.0102 - val_accuracy: 0.8600 - val_loss: 0.5870\n",
      "Epoch 38/40\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 832us/step - accuracy: 0.9971 - loss: 0.0110 - val_accuracy: 0.8690 - val_loss: 0.5997\n",
      "Epoch 39/40\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - accuracy: 0.9977 - loss: 0.0119 - val_accuracy: 0.8690 - val_loss: 0.6099\n",
      "Epoch 40/40\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 798us/step - accuracy: 0.9984 - loss: 0.0119 - val_accuracy: 0.8700 - val_loss: 0.6186\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,400</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">68</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │        \u001b[38;5;34m16,400\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │            \u001b[38;5;34m68\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m5\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">49,421</span> (193.05 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m49,421\u001b[0m (193.05 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,473</span> (64.35 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m16,473\u001b[0m (64.35 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">32,948</span> (128.71 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m32,948\u001b[0m (128.71 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "best_hp = tuner.get_best_hyperparameters()[0]\n",
    "nn_model = tuner.hypermodel.build(best_hp)\n",
    "nn_model.fit(X_train, y_train, epochs=40, validation_data=(X_val, y_val))\n",
    "nn_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 360us/step - accuracy: 0.9996 - loss: 0.0080\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 504us/step - accuracy: 0.8816 - loss: 0.4925\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9986363649368286, 0.8700000047683716)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train_accuracy = nn_model.evaluate(X_train, y_train)[1]\n",
    "val_accuracy = nn_model.evaluate(X_val, y_val)[1]\n",
    "train_accuracy, val_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'C': 10.0, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "Best cross-validation score:  0.9168181818181818\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "### SVM\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Define the parameter grid for grid search\n",
    "param_grid = {\n",
    "    'C': np.logspace(-3, 2, base=10, num=6),\n",
    "    'kernel': ['rbf', 'sigmoid'],\n",
    "    'gamma': np.logspace(-3, 2, base=10, num=6)\n",
    "}\n",
    "\n",
    "# Perform grid search to find the best parameters\n",
    "grid_search = GridSearchCV(SVC(), param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters: \", grid_search.best_params_)\n",
    "print(\"Best cross-validation score: \", grid_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9963636363636363\n",
      "Val accuracy: 0.875\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create an SVM model with the best parameters\n",
    "svm_model = SVC(**grid_search.best_params_)\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "print('Train accuracy:', accuracy_score(y_train, svm_model.predict(X_train)))\n",
    "print('Val accuracy:', accuracy_score(y_val, svm_model.predict(X_val)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
